terraform:: it is an infrastructre as code
====
->Terraform is an Infrastructure as Code (IaC) tool used for automating the provisioning, management, and versioning of cloud infrastructure resources.
->terraform written on go language and is uses in HCL language
->why we need to use t/f?
Ans)client needs an application -->where we need to create application inside server for that vpc,storage all those things we need and
 if the application got heavy load at that time loadbalancer will be involved this is called as infrastructure.
->using t/f we can create infrastructure in an automation way
->if we go any organization there will use terraform
->in aws(CFT)is the automation way of craeting infrastructure[in tz  we can write code and convert into t/f]
->in aws CFT and in azure we have ARM template and gcp we use GDE but we can work t/f with any cloud even kbs also used t/f.
->using t/f we can work with any cloud.it is cloud aganist.
->if we deploy anything we use docker[used to create container]or ansible for that required t/f
->using t/f we can handle both low-level elements like networking,storage,compute instances,also high level elements
like SAAS features,DNS entries etc..
-->terraform is server orchestartion tool[means we can create infrs end to end][chef,ansible and puppet are configuration management tool]
->what is ansible will do? using ansible we can manage all servers while t/f is used to crate server.
->terraform supports hashicorp language not yaml
->https://releases.hashicorp.com/terraform (we get all versions of terraform)
**)if we install any package that will go into the etc folder
->ami-id will change from one region to another region
Treeaform blocks[using tz we can create t/f]::
=================
1)provider&region[prakashraj[PR]]
2)resource configuration[RamCharan[RC]]
3)variable declaration[VijayDevarakoda[VD]]
-->aws configure will give the security credentials and integrated with third party tools.
-->kops is a thirdparty open source tool and we integrate that with the aws using aws configure

steps[t/f life cycle]::
=======
terraform init (i) -->intializing aws provider plugins
terraform validate -->it is used to check the syntax validations
terrraform plan(p) -->it is used to create execution plan
terraform apply(a) -->craeting resource
terraform destroy(d)

1)simple t/f::
==========
provider "aws" {
region = "us-east-2"
}

resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
}

2)using variable::[calling the instance type]
==========
provider "aws" {
region = "us-east-2"
}

resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = var.instance_type
}

variable "instance_type"{
description = "iam using this block for instance type"
type = string
default = "t2.micro"
}

3)creating t/f with 2 servers::[simple creation of count variable]
========================
provider "aws" {
region = "us-east-2"
}

resource "aws_instance" "one" {
count = 2
ami = "ami-019f9b3318b7155c5"
instance_type = var.instance_type
}

variable "instance_type"{
description = "iam using this block for instance type"
type = string
default = "t2.micro"
}

4)creating count using variable::
=======
provider "aws" {
region = "us-east-2"
}

resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = var.instance_count
}

variable "instance_count"{
description = "iam using this block for instance type"
type = number
default = 3
}

5)creating iam users using t/f [list of strings]::
===================
provider "aws" {
region = "us-east-2"
}

/*resource "aws_instance" "one" {
count = var.instance_count
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
}*/                                                /* commenting #[for single line]

resource "aws_iam_user" "two" {
count = length(var.iam_users)
name = var.iam_users[count.index]
}

variable "iam_users" {
description = "iam using this block for instance type"
type = list(string)
default = ["kamalesh", "ravi", "manju", "suman"]
}
6)using map creating iam users::
===========
provider "aws" {
  region = "us-east-2"
}

resource "aws_iam_user" "one" {
  for_each = var.iam_users
  name     = each.key
}

variable "iam_users" {
  description = "Map of IAM users to create"
  type        = map(string)
  default     = {
    "kamalesh" = "kamalesh"
    "ravi"     = "ravi"
    "manju"    = "manju"
    "suman"    = "suman"
  }
}


into,iaac,why,alternatives,advantages

basic commands
ec2,iam
vars:: list,map,string,numbers

when we want use only variable in terrafrom we can follow the below procedure
create main.tf and carete variable.tf
main.tf:
==========
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = var.instance_type
tags = {
Name = "shruthi"
}
}

variable.tf::
==================
variable "instance_type" {
description = ""
type = string
default = "t2.micro"
}

check terraform.tfstate an instnace will be created
->when we destroy [terraform destroy --auto-aprrove] and check terraform.tfstate[it wont show any instance]

2nd way:: terraform tfvar files by using tz we can segregate the variables.here for instance_type we make two file[variable.tf and swiggy.tfvar][advantage with terraform tf var files if we want to edit(or)work with only variables at that time we use variables concept]
======
main.tf::  in this searching for variable file i.e. var.instance_type
============
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = var.instance_type
tags = {
Name = "shruthi"
}
}
variable.tf:: here we have variable block will be present
===========
variable "instance_type" {
}

swiggy.tfvar:: here we have instance_type
==================
instance_type = "t2.micro"

->then run terraform apply --auto-approve
->will get below like tz::
var.instance_type
  Enter a value: t2.micro
->terraform destroy  --auto-approve

same as the above code but some modifications when we use .tfvar it will ask the instance_type but when we use .
tfvars it wont ask any instance_type in that case we need to be mentioned in command like:
->terraform apply -var-file="swiggy.tfvars" --auto-approve [THEN IT WONT ASK THE INSTANCE_TYPE]

and follow below code::
main.tf::
==========
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = var.instance_type
tags = {
Name = "shruthi"
}
}
variable.tf::
===========
 variable "instance_type" {
}

swiggy.tfvar::
==========
instance_type="t2.micro"
 
==>terraform fmt [to arrange the file in a proper format]

if we work with "multiple tfvar files" clients then we can use below as follows::
main.tf::
==========
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = var.instance_type
tags = {
Name = var.instance_name
}
}
zomato.tf::
============

variable "instance_type" {
}
variable "instance_name" {
}

zomato.tfvars::
============
instance_type="t2.micro"
instance_name = "zomato"

swiggy.tf::
===============
variable "instance_type" {
}
variable "instance_name" {
}

swiggy.tfvars::
=============
instance_type="t2.micro"
instance_name = "swiggy"


==>terraform apply --var-file="zomato.tfvars" --auto-aprrove
==>terraform apply --var-file="swiggy.tfvars" --auto-aprrove
terrafrom cli:;
===========
==>we can pass the ami_id using cli:: code as below follows
-->passing varaible through cli[eg::ami_id]
main.tf::
===========
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = var.ami_id
instance_type = "t2.micro"
tags = {
Name = "abcd"
}
}

variable "ami_id" {
}

-->terraform apply -var="ami_id=ami-019f9b3318b7155c5"
-->
how to pass  variable in 4 ways::
1)main.tf 2)variables file 3)tfvarfiles 4)through cli

2,3 in real life

terraform outputs::
=======================
when we create an instance automatically public_ip address will be created here from the code i need to get the public+ip through as in mentioned in the outputs
main.tf:: we wnat multiple values we use arrays[eg::value = [aws_instance.one.public_ip,aws_instance.one.private_ip,aws_instance.one.public_dns]]
=====
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
tags = {
Name = "abcd"
}
}

output "props" {
value = [aws_instance.one.public_ip,aws_instance.one.private_ip,aws_instance.one.public_dns]
}
o/p::
props = [
  "3.140.245.93",
  "172.31.21.249",
  "ec2-3-140-245-93.us-east-2.compute.amazonaws.com",
]
uptonow topics::variable.tf,tfvars,multitfvars,terrafrom cli,t/f outputs

s3 bucket creation::
=================
main.tf::
=============
provider "aws" {
region = "us-east-2"
}
resource "aws_s3_bucket" "example" {
  bucket = "my-tf-test-bucket"  
}

creating ebs volume:
====================
-->ebs volumes will be stored based on avaliablity zone(us-east-2a) like that way
-->ec2 will be on region level and ebs volume will be creeated based on avaliablity zone.
 
46 video::
=================
terraform local:: once we create t/f local we cant change the value.
======
24:04

47 video::[44:58]
===========
creating s3 bucket by using backend block::

provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
tags = {
name = "webserver"
}
}

terraform {
backend "s3" {
bucket = "raham889977"
key = "swiggy/prod/terraform.tfstate"
region = "us-east-2"
}
}
terraform boolean values::
==========================
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "one" {
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
associate_public_ip_address = var.enable_public_ip
tags = {
name = "webserver"
}
}

variable "enable_public_ip" {
description = ""
type = bool
default = true
}
terraform {
backend "s3" {
bucket = "raham889977"
key = "swiggy/prod/terraform.tfstate"
region = "us-east-2"
}
}
-->we are giving variable block in default=true so in thaqt case at the time of instance creation public ip address is created.
--->if we change any properties in main.tf file we can apply (terraform init --auto-approve) then changes will be apply like i.e. '~'symbol.
-->terraform state list(to know how many resources are created in our terraform file)

dynamic block,efs,local resource,backend configuration,version constraints,boolena values,terraform statelist
48 videos::
===============
creating multiple resourcers using t/f::
===================================
1)concept[target]::
============
provider "aws" {
region = "us-east-2"
}
resource "aws_ebs_volume" "one" {
availability_zone = "us-east-2a"
size = 40
tags = {
Name = "Helloworld"
}
}
resource "aws_s3_bucket" "two" {
bucket = "shr2503"
}

resource "aws_instance" "three" {
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
tags = {
Name = "web-server"
}
}
->terraform init
->terraform validate
->terraform apply --auto-approve
->terraform state list
-->terraform destroy -target = "aws_s3_bucket.two" [destroying only single resource]
 lifecycle meta-arguments::
=========
-->prevent_destroy
-->create_before_destroy
-->ignore_changes
2))concept[prevent_destroy]::
===========
provider "aws" {
region = "us-east-2"
}
resource "aws_ebs_volume" "one" {
availability_zone = "us-east-2a"
size = 40
tags = {
Name = "Helloworld"
}
}
resource "aws_s3_bucket" "two" {
bucket = "shr2503"
}

resource "aws_instance" "three" {
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
tags = {
Name = "web-server"
}
lifecycle {
prevent_destroy = true
}
}

==>terraform destroy --auto-approve [when we enter this s3 and ebs_volume will deleted  but  ec2 not deletd will have some lifecycle policy]
==>terraform state list
  aws_ebs_volume
  aws_s3_bucket
  aws_instance
3)create_before_destroy::
provider "aws" {
region = "us-east-2"
}
resource "aws_instance" "three" {
ami = "ami-019f9b3318b7155c5"
instance_type = "t2.micro"
tags = {
Name = "web-server"
}
lifecycle {

create_before_destroy = true
}
}
resource "aws_ebs_volume" "one" {
availability_zone = "us-east-2a"
size = 40
tags = {
Name = "Helloworld"
}
}
resource "aws_s3_bucket" "two" {
bucket = "bingi2503"
}
==>terraform destroy --auto-approve [everything will be deleted]
==>terraform state list(will get list of resources)
==>create_before_destroy  we pply to any of the resource and if we apply [terraform destroy] then it will delete that resource and again it will create new resource and delte the old one

==>prevent_destroy if we apply to any resource it wont delete at the time of applying the [terraform destaroy]it will throw an error.

terraform taint:: when object is not working properly and we wnat to recreate that particular object[like ec2] then in that case it will be used.
eg:::
provider "aws"{
regoion = "us-east-1"
}
resource "aws_istance" "one"{
ami ="123"
instance_type= "t2.micro"
tags={
Name= "ec2-server"
}
}
resource "aws_s3_bucket" "two" {
bucket = "bingi"
}
==>terraform taint aws_instance.one [in this only we need to create only one ec2 resource recretea it.]
resource instance aws_instance.one has been marked as tainted.
==>terraform plan
==>terraform apply --auto-approve[only ec2 will be recreted]
=>terraform taint and replace will work for same purpose.
terraform apply  -replace ="aws_instance.one" [old instance will be deletd and new instance will be created] ,(replace is the alternative concept for taint)
what is the difference b/n taint and target?
-->if there are 3 objects are not working properly then we can target command 3 times where as taint command we can use single command
main.tf::
==================
terraform modules::
===================
-->ansible roles:: playbook divided into priorities.so organizing playbook into a particular format is called ansible roles.
role is used to organize the playbook into a directory format.

-->same in t/f modules are going to organize the infrastructre into the directory structure.

├── main.tf
├── modules
│   ├── buckets
│   │   ├── main.tf
│   │   └── variable.tf
│   └── instances
│       ├── main.tf
│       └── variable.tf
├── provider.tf
├── terraform.tfstate
└── terraform.tfstate.backup
-->mkdir modules
-->mkdir modules/instances
-->mkdir modules/buckets
-->cd instances
main.tf::
===============
resource "aws_instance" "my_instance" {
ami = var.ami
instance_type = var.instance_type
tags = {
Name = var.instance_name
}
}
varaible.tf::
=================
variable "ami" {
type = string
}
variable "instance_type" {
type = string
}
variable instance_name {
description = "value of the name tage c2 instace"
type = string
}
cd buckets::
================
main.tf::
========
resource "aws_s3_bucket" "b" {
bucket = var.bucket_name
}
variable.tf::
=============
variable "bucket_name" {
type = string
}
==>sudo yum install tree -y
==>terraform init
==>terraform apply
terraform cloud:: where we can create our t/f resources on t/f platform.

overall concepts::
************************

into,iaac,why,alternatives,advantages

basic commands
ec2,iam
vars:: list,map,string,numbers

how to pass  variable in 4 ways::
1)main.tf 2)variables file 3)tfvarfiles 4)through cli

2,3 in real life



uptonow topics::variable.tf,tfvars,multitfvars,terrafrom cli,t/f outputs

dynamic block,efs,local resource,backend configuration,version constraints,boolena values,terraform statelist

target and taint

 lifecycle meta-arguments::
=========
-->prevent_destroy
-->create_before_destroy
-->ignore_changes

terraform modules::
===================
-->ansible roles:: playbook divided into priorities.so organizing playbook into a particular format is called ansible roles.
role is used to organize the playbook into a directory format.

-->same in t/f modules are going to organize the infrastructre into the directory structure.

Terraform Backend	Defines where Terraform stores the state (local, S3, Terraform Cloud, etc.)
Terraform State File (terraform.tfstate)	JSON file that tracks the current state of infrastructure

